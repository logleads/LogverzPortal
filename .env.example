#REGION=string
#ACCOUNT_NUMBER=number
#BASE_URL=https://some.url
#STAGE_NAME=string
RTC_PORT=3478
AD_HTML_TAG = <ins data-revive-zoneid="4" data-revive-id="2f546c30ad8d4b80838351c12a4786b1"></ins>
AD_HTML_TAG_ID = 2f546c30ad8d4b80838351c12a4786b1
AD_SCRIPT_SRC = //adserver.logleads.com/www/delivery/asyncjs.php

###########
DCH_AVAILABLE_BUCKETS=The list of buckets available in the current account please note that accessing data in remote buckets may have slower performance and increased cost.
DCH_S3_FOLDERS=Semi Colon (;) separated list of folders containing the log files. Specify it as s3://bucket/folder/any/number/of/subfolders; s3://otherbucket/folder/subfolder; etc.
DCH_LOG_VOLUME=To allocate the necessary resources, please specify the number of log files to be processed. Job will be configured accordingly. Small: number of files up to 5M and less than 20 GB. Medium: number of files 5M-25M and less than 100GB. Large:number of files over 25M and 100GB.
DCH_QUERY_TYPE_SELECTOR=The dataformat/schema of the files located in the specified S3 bucket(s).
DCH_DB_SERVER_ALIAS=The friendly/short name of the target database server.
DCH_TABLE_NAME=Dataset is a DB table, a name convention such as team_projectname_task or personname_issue_number max 63 charachters, is recommended.Please specify a unique name, otherwise the existing dataset will be overwritten.
DCH_TABLE_DESCRIPTION=You can record here the settings used to create the dataset (DB table), like logs creation intervall time, services involved, api call types purpose of the data any additional information on retention or sharing instructions.
DCH_TABLE_OWNERS=Besides the creator, who is automatically the owner of the dataset (DB table), you can specify here addititional users and IAM groups, who can read delete and grant permissions to the table.
DCH_TABLE_ACCESS=You can specify here addititional users and IAM groups, who will have read access to the dataset (DB table).
DCH_S3_ENUMERATION_DEPTH=To achieve maximum speed file processing needs to happen parallel.It works by listing subfolders and working on subfolders individually.This parameter controls how deep enumeration should go. Select a setting where the number of subfolders (as seen in the logs) are between approximately 40 - 400 as that provides the optimal level of parallelisation. Going much deeper only increases the execution time.
DCH_PREFERRED_WORKED_NUMBER=You can specify the number of worker lambdas running in parallel. For most cases automaticaly determined setting is correct. If you specify a number keep in mind selected controller capabilities, aws account limits and check concurrent executions
DCH_ALLOCATION_STRATEGY=The way small to large jobs are scheduled. 'cost-sensitive': small jobs run only on small controllers, medium jobs run only on medium controller as they become available.'time-sensitive': small and medium jobs can run on any controller including Large. 'balanced': small jobs will prefer small controller, if none available use medium controller, medium jobs will prefer medium controller, if none available use large controller. In all cases large jobs only use large controller.
DCH_QUERY_HISTORY=Filters on the Active property of the record, 'Current' (Active true) means that dataset (DB table) is present and queriable, All (Active any) means previous overwritten datasets are also shown. 

###########

AW_NAME=You provide the name of the user,example Bob@Google or Bob@Facebook. The name must match the identity providers name usually the part of the e-mail address before the @. 
AW_TYPE=Select from the enabled external identity providers. If list is empty and you want to allow external users such as @google users, please check documentation on the necessary steps. 
AW_GROUPS=Assign user to existing groups inheriting the permissions of the group.
AW_POLICIES=Assign users policies directly to add access to additional resources.

###########
USR_RTC_DESCRIPTION=Setting controls the requests path, some network configuration direct connection is not possible requests are routed trough turnservers. If experiencing WebRTC connection delays try switching settings